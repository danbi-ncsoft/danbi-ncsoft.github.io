---
layout: post
title:  "게임 고객 LTV 추정하기"
date:   2020-03-16 18:00:00
categories: Works
author : DANBI
cover:  "/assets/works/mobile_mkt/title_mobile_mkt.jpg"
---



## 배경

일전에 앱 마케팅 분석 소개와 더불어, 데이터센터 내에 다양한 게임 활동 로그를 활용한 고도화된 모바일 마케팅 지표를 [1편](https://danbi-ncsoft.github.io/works/2019/08/06/works-mobile_mkt-1.html)과 [2편](https://danbi-ncsoft.github.io/works/2019/08/19/works-mobile_mkt-2.html)에 걸쳐 소개 드렸었는데요. 오늘은 그 이후에 진행한 작업으로 게임 고객의 LTV 지표를 개선한 내용에 대해 소개 드리려고 합니다. 

**LTV 란?**

고객 생애 가치를 의미하는 LTV(Life Time Value)란, 유저가 앱을 사용하는 그 일생 동안 얼마만큼의 이익을 가져다 줄 것인지를 돈으로 계산한 것으로 CLV(Customer Life time Value)라고 표현하기도 합니다. 일반적으로 LTV의 개념은 다음과 같은 식으로 표현할 수 있고, 더 정확하게는 이자율이나 할인율 등을 고려하여 계산할 수 있습니다.

$$LTV$$  
$$=$$ (첫 해에 고객이 가져다 준 이익의 총합) $$-$$ (신규 고객 유치에 들어간 비용)   
$$+$$ (둘째 해에 고객이 남아 있을 확률)$$\times$$((둘째 해에 고객이 가져다 준 이익의 총합) $$-$$ (고객 유지에 들어간 비용))  
$$+$$ (셋째 해에 고객이 남아 있을 확률)$$\times$$((셋째 해에 고객이 가져다 준 이익의 총합) $$-$$ (고객 유지에 들어간 비용)) $$+ \cdots$$

즉, LTV의 관점으로 고객을 보면, 단순히 당장의 매출을 높이는 것에만 집중하는 것이 아닌 고객 유치 비용과 고객 유지 비용을 최적으로 줄이는 것이 중요하며, 계속해서 높은 고객 유지 비율을 유지하는 것이 중요합니다. 게임에서도 비슷하게, 지금 당장의 매출을 높이는 것 보다 여러 마케팅 비용은 최소한으로 줄이되, 유저들이 계속해서 다시 찾는 게임을 만드는 것이 LTV를 높이는데 중요한 것 이죠.

이에 초기 데이터로 LTV를 추정하는 것은 정확한 마케팅 효과 측정 측면에서나 게임의 라이프 싸이클 모니터링 등에 있어 매우 중요한 과제입니다. 저희는 이러한 LTV의 중요성을 인지하고, (1) 등비 수열을 이용한 방식으로 LTV 지표를 제공하고 있었습니다. 추가적으로, 앱을 사용하는 일생까지는 아니지만, 향후 한 달(또는, 일주일)간 고객 가치를 (2) 예측 모델을 이용하여 제공하고 있었습니다. (LTV의 보다 자세한 내용은 [이 포스팅]( https://sungmooncho.com/2011/11/21/customer-lifetime-value/를 참고하시기 바랍니다.)를 참고하시기 바랍니다.)

**(1) 등비 수열을 이용한 LTV 추정**

(1) 방식은 초반의 단위 기간 당 ARPU(평균 결제 금액)와 리텐션(잔존율)이 향후에도 반복된다는 가정을 갖고, LTV를 계산한 방식입니다. 앞서 말씀 드렸던 LTV 개념에 이러한 가정을 적용하여 추정 식을 작성해보면, 아래와 같이 나타낼 수 있습니다.

$$\hat{LTV}$$  
$$=$$ (첫 달(또는, 첫 일주일)에 고객이 가져다 준 이익의 총합) $$+$$ (둘째 달에 고객이 남아 있을 확률)$$\times$$(둘째 달에 고객이 가져다 준 이익의 총합) $$+$$ (셋째 달에 고객이 남아 있을 확률)$$\times$$(셋째 달에 고객이 가져다 준 이익의 총합) $$+ \cdots$$  
$$=$$ (단위 기간 당 ARPU) $$+$$ (단위 기간 당 ARPU)$$\times$$(단위 기간 당 리텐션) $$+$$ (단위 기간 당 ARPU)$$\times$$(단위 기간 당 리텐션)$$^2 + \cdots$$

즉, 유저의 단위 기간 당 ARPU를 첫 째 항, 단위 기간 당 리텐션을 공비로 하는 등비 수열로 보고 이 수열을 무한 합하여 $$\frac{ARPU}{1-리텐션}$$와 같이 LTV를 계산하는 방식입니다. 이 방식은 매우 직관적이고 계산 방식도 비교적 쉽습니다. 하지만 실제 저희 게임의 단위 기간 당 ARPU와 리텐션을 살펴보면 초반의 단위 기간 당 값이 향후에 비슷하게 반복되지 않습니다. 아래 그림과 같이 변동성이 매우 커서 이런 방식으로 추정치를 계산하면 정확하지 않게 되죠. 

<p align="center">
<img src="/assets/works/mobile_mkt/ltv1.PNG" style="width:9in" />
[그림1] 모델 가정과 맞지 않는 실제 우리 게임의 리텐션과 ARPU 변동성
</p>


**(2) 예측 모델을 이용한 가치 추정 (생애 가치보단 향후 매출 예측에 가까움)**

(2) 방식은 RFM 피쳐를 기반으로 기계 학습 알고리즘 중 하나인 Random Forest 모델을 적용하여 향후 30일이나 7일간의 매출을 예측한 방식입니다. 여기서 RFM 이란, 거래의 최근성(Recency), 빈도(Frequency), 규모(Monatary)를 의미하며, 마지막 구매 이후 기간, 총 구매 횟수, 총 구매 금액 등을 피쳐로 추출하여 Random Forest 모델을 적용한 후 향후 매출을 예측한 지표입니다. 이 방식은 (1) 방식과 같은 가정이 필요없지만, 생애 가치인 LTV와 의미적으로 차이가 있습니다. 

이 방식을 생애 가치인 LTV 관점에서 예측하려하면 라벨 데이터 확보가 매우 어렵고, 지금처럼 향후 7일이나 30일 매출 예측으로 범위를 축소하더라도 정확한 예측 모델을 만들기 어렵습니다. 모델링에 사용할 안정적인 피쳐 선택이 어려울뿐더러 시간이 지남에 따라 예측 모델의 정확도가 점점 떨어지게 되기 때문입니다.  

<p align="center">
<img src="/assets/works/mobile_mkt/ltv2.PNG" style="width:6in" />
[그림2] 정확도가 매우 떨어진 RFM 모델의 최근 예측치와 실측값
</p>
이렇게 (1) 방식과 (2) 방식이 가진 각각의 단점을 보완하기 위해, (1) 방식의 단위 기간을 조정하거나 (2) 방식의 예측 기간을 조정하는 등 여러 가지 방식의 지표를 모두 제공하고 있었는데요. 문제는 각 추정치들이 값의 편차가 커, 우리 게임의 LTV가 그래서 얼마라는 것인지 오히려 사용자에게 혼란을 주고 있었습니다.



## 분석 목표

**일반적인 기법 개발하기**

기존 제공 지표의 단점을 보완하고 보다 정확한 하나의 지표로 통합하는 작업을 위해, 모든 게임에서 공통적으로 사용할 수 있는 최대한 일반적인 기법을 개발해야 했습니다. 별도의 피쳐 데이터나 라벨 데이터를 확보하지 않고 ARPU와 리텐션 데이터만을 이용하여 LTV 값을 추정하되, 기존 방식보다는 조금 더 정교한 기법을 고안해야 했습니다. (미리 살짝 말씀 드리자면, 개선된 지표는 평생 가치를 예측하는 LTV의 개념보다는 각 기간별 예상 수익을 추정하는 것과 좀 더 가까워, 지표의 명칭도 “예상 수익” 지표로 변경하게 되었습니다.)

**신속하게 추정하되, 시간이 지남에 따라 정확해지는 추정치 만들기**

추가적으로 게임 론칭 후 최소 일주일 이내에 추정치가 나오도록 신속하게 지표를 제공하는 것을 목표로 하였습니다. 따라서 최초 7일 간의 집계 정보에서부터 (예측력이 조금 떨어지더라도) LTV를 추정하고, 시간이 지남에 따라 일 단위로 데이터를 누적하여 성능을 높여갑니다. 기존 추정치에 이용했던 정보와 새롭게 쌓이는 정보를 결합하여 추정치를 보완하도록 모델링합니다. 또한 리텐션 측정시 별도의 시간을 들여 이탈 여부를 판단하지 않고 일별 접속률을 이용하여 즉각적으로 모델에 활용합니다. 

예를 들어, 게임 론칭 시점이 1월 1일이라고 가정하면, 1월 1일에 접속한 유저의 1월 7일까지의 7일간 일별 ARPU와 리텐션 데이터를 집계하여 1월 7일에 신속하게 지표를 추정합니다. 1월 8일 추정치에는 1월 1일에 접속한 유저의 1월 8일까지의 8일간 정보와 1월 2일에 접속한 유저의 1월 8일까지의 7일간의 정보를 결합하여 추정치를 보완합니다. 1월 9일 이후 추정치도 비슷한 방식으로 누적된 데이터를 활용하여 점차 정확한 추정값을 얻을 수 있습니다. (참고로, 무한하게 과거 데이터를 누적할 경우 모델 노후화 문제나 연산량 문제가 발생하므로, 예측의 정확성과 로직별 소요시간을 절충하여 최근 30일 정도의 접속 유저에 대한 정보를 집계하여 모델에 사용하였습니다.)



## 상세 기법

**단위 기간 당 ARPU 추정하기**

ARPU 추정은 사실상 대규모 업데이트 시기와 같은 특정 날짜에 따라서 값의 편차가 매우 컸기 때문에, 아래에서 소개해드릴 리텐션 추정과 같이 함수 피팅 방식이나 확률 분포를 이용한 방식으로는 추정하기 어려웠습니다. 이러한 일자별 변동성을 완화시키되 학습 기간 동안의 평균적인 값을 반영할 수 있도록 일자별 ARPU의 이동 평균을 구하는 방식으로 추정을 대체하여 변동성에 강건해지도록 전처리 하였습니다. 

<p align="center">
<img src="/assets/works/mobile_mkt/ltv3.PNG" style="width:6in" />
[그림3] 일자별 ARPU와 ARPU의 이동 평균 비교
</p>

위 그래프에서 보시는 바와 같이 일자별 ARPU는 특정 날짜에 따라 튀는 경우가 발생하지만, ARPU의 이동 평균을 구하면 튀었던 값들과 아닌 값들의 평균을 구하게 되므로 변동 폭이 많이 완화된 것을 확인 할 수 있습니다.

**단위 기간 당 리텐션 추정하기**

일반적으로 유저의 이탈 여부를 판단하기 위해서는 특정 기간 동안 유저를 관찰하며 일정 기간 이상 미접속인 경우를 확인해야 합니다. 따라서 이탈 여부를 판단하려면 시간이 오래 걸리고 리소스도 많이 듭니다. 정확한 추정도 중요하지만, 데이터 집계부터 너무 오래 걸리거나 과한 리소스를 사용하게 되면 다른 서비스에 영향을 주면 안되겠죠?

그래서 리텐션 측정 시 별도의 이탈 여부를 판단하지 않고 접속률을 이용하여 추정하는 방식을 사용하여 시간을 절약했습니다. 예를 들어, 1월 1일(기준일)에 접속한 유저가 100명 이라면, 기준일에 접속한 100명 중 1월 2일에 접속한 유저는 50명, 또 기준일에 접속한 100명 중 1월 3일에 접속한 유저는 55명 등으로 접속률을 $$\frac{100}{100}$$, $$\frac{50}{100}$$, $$\frac{55}{100}$$와 같이 구할 수 있습니다.

이 때, 접속률 정보만을 사용하였기에 일반적인 감소 형태의 리텐션 그래프가 아닌, 전반적으로는 감소하나 일부 상승하는 일자도 있는 형태로 그려졌는데요. 추정 결과의 정확성을 위해 약간의 데이터 전처리가 필요했습니다. 접속률이 전날보다 상승한 경우, 이전 시점까지 접속률 중 최소값으로 대체하여, 시간에 따라 감소하는 형태가 되게 처리하였고 추정의 정확성을 높일 수 있었습니다.

<p align="center">
<img src="/assets/works/mobile_mkt/ltv4.PNG" style="width:6in" />
[그림4] 특정 날짜의 리텐션 데이터 전처리 전후 모델링 결과 비교. 이와 같이 유독 접속률 변동이 큰 날은 전처리 없이 그냥 사용하면 추정의 정확성이 매우 떨어집니다.
</p>
리텐션은 함수 피팅 값과 sBG(shifted Beta Geometric) 모델 값을 조합하여 추정하였습니다. 저희 게임 기준으로, 함수 피팅 값은 실측값보다 under-fitting 되는 경향이 있었으며, sBG 모델 값은 over-fitting 되는 경향이 있었기에 두 방식의 평균을 사용하였고, 간혹 함수 피팅 방식에서 파라미터 추정이 불가능한 일자에는 sBG 모델만을 사용하였습니다.  

먼저, 함수 피팅의 경우, 데이터를 잘 알려진 형태의 함수로 적합시키는 것을 의미하는데요. 유저의 리텐션 그래프가 분수 함수 즉, $$\frac{1}{t}$$이나 $$\frac{1}{t^2}$$ 꼴과 비슷하게, 처음에 급격하게 감소하며 시간이 무한히 지나면 $$0$$ 에서 수렴하는 꼴을 갖기 때문에, 분수 함수 개형인 $$\frac{d}{b \cdot t^a + c}$$를 사용하였습니다. 분수 함수 개형의 파라미터 $$a$$, $$b$$, $$c$$, $$d$$ 는 비선형 최소 제곱법 방식을 이용하여 구합니다. 비선형 최소 제곱법 방식은 $$t$$에 따라 비선형 함수 피팅값(미리 정의한 분수 함수 개형의 함수값)과 실측값(저희 리텐션 데이터)의 잔차 제곱 합이 최소가 되도록 하는 최적의 파라미터를 구하는 알고리즘입니다. 

하지만 함수 피팅 방식은 미리 리텐션에 대한 사전 정보를 알고 함수의 개형을 정해주어야 하는데요. 이와 다른 접근으로 사전 정보가 없더라도 리텐션을 모델링 할 수 있는 방식도 고려해보았습니다. sBG 모델의 경우는 기하/베타 분포를 이용하여 리텐션을 모델링 하는 방식입니다. 확률분포에 의거하여 구하는 방식이기 때문에 함수 피팅 방식과 달리 리텐션의 개형을 미리 정의하지 않아도 사용이 가능합니다. sBG 모델은 유저의 이탈 확률이 베타 분포를 따른다고 가정하고, $$t$$ 시점에서의 이탈 확률과 생존 확률을 계산하여 리텐션 함수를 모델링하는 알고리즘입니다. 자세한 내용은 Appendix로 추가합니다.

<p align="center">
<img src="/assets/works/mobile_mkt/ltv5.PNG" style="width:6in" />
[그림5] 초반 데이터를 가지고 리텐션을 추정하여 후반 리텐션이 잘 적합되었는지 살펴보면,  
함수 피팅 방식은 under-fitting 경향이 있고 sBG 모델 방식은 over-fitting 되는 경향이 있어 두 방식의 평균을 사용하였습니다. 
</p>
**고객 가치 추정하기**

위에서 추정된 리텐션과 매출을 이용하여, 최종 예상 수익 지표는 다음과 같이 계산합니다!

$$\hat{예상수익} = \hat{매출} \times \sum_{0≤t≤period} \hat{리텐션} $$

이 때, LTV의 의미상 평생 가치를 측정하기 위해서는 리텐션이 $$0$$으로 수렴하는 $$t$$ 시점 까지 합 해야 하지만, 수렴하는 곡선이 완만해서 LTV가 지나치게 높게 추정되는 문제가 있었습니다. 애초에 수십년 동안의 누적 가치를 추정하는 것은 의미가 없다고 판단하였고, 실제 사업에서 1년 단위 매출을 추정하는 것이 중요하기 때문에, period를 30/90/180/365일로 나누어 단기/중기/장기 예상 수익 값을 제공하게 하였습니다. (서비스 명칭도 LTV에서 예상 수익으로 변경!) 또한 단순히 하나의 값으로 예상 수익을 추정하기 보다는 리텐션과 매출의 표준 오차를 활용하여 99% 예상 수익 신뢰구간을 계산하여 함께 제공하였습니다. 신뢰구간 세부 계산 식은 Appendix로 추가합니다.

<p align="center">
<img src="/assets/works/mobile_mkt/ltv6.png" style="width:9in" />
[그림6] 개선된 LTV 지표 기획안 일부 발췌
</p>

**추정 모델의 정확도 평가**

예상 수익 추정은 기존 LTV 지표 대비 오차율을 절반 이상 감소시켜 지표의 정확성도 증대시켰습니다. 각기 다른 방식으로 계산된 추정치이기에 180일 추정으로 기준을 통일하여 MAPE(Mean Absolute Percentage Error, $$\frac{1}{n} \sum \frac{ \|실측치-추정치\| }{실측치} \times 100$$)를 계산하였을 때, 결과적으로 기존 지표 중 가장 좋은 값과 비교하여도 50% → 18%로 대폭 감소하였습니다.

<p align="center">
<img src="/assets/works/mobile_mkt/ltv7.png" style="width:5in" />
[그림7] 개선된 방식과 기존 방식의 MAPE 비교
</p>

**세그먼트별 추정치  집계**

추가적으로 저희가 모델링하는 대상은 유저들의 평균적인 생애 가치인데요. 실제로는 각 유저마다 갖는 가치가 매우 편차가 큽니다. 우연히 게임을 다운로드 하게 되어 하루만 플레이 해보고 그 이후로 접속을 안 하는 유저가 있을 수도 있고, 오랜 기간동안 다양한 컨텐츠를 즐기는 유저일 수도 있죠. 그러므로 이러한 편차를 줄이기 위해선 비슷한 성향의 유저군을 세그먼테이션 한 후에 각 세그먼트별로 가치를 측정하여 본다면 지표에 대한 신뢰도를 좀 더 높일 수 있을 것입니다. 더 나아가 이렇게 세그먼트 별로 가치를 추정하면 좀 더 정교한 고객 관리나 마케팅이 가능합니다. 따라서 저희 데이터에 기록되는 신규 유입 여부, os 구분, 광고 매체 유입 여부, 에뮬레이터 사용 여부 등의 정보를 활용하여 각 세그먼트별 평균적인 가치를 측정하여 활용성 높은 정보를 전달하도록 했습니다.

## 마치며

이번 포스팅에서는 LTV 지표 개선 작업에 대한 내용을 공유드렸었는데요. 최소 7일간의 접속률(이탈 고려 x) 및 결제 정보 집계를 시작으로 신속하게 지표를 제공하고, 시간이 지남에 따라 누적된 데이터를 활용하여 점차 정확한 추정치를 만드는 과정을 소개드렸습니다. 앞으로 새롭게 제공되는 **예상 수익** 지표는 일별 ARPU의 이동평균값으로 ARPU를 추정하여 과거 특수한 날짜들의 변동성을 줄이고, 분수 함수 피팅 방식과 sBG 모델을 이용하여 리텐션을 정교하게 추정하였기에, 기존 지표 보다 훨씬 정확한 추정값을 갖습니다. (기존 대비 MAPE가 50 → 18%) 더불어 유저 세그먼트별 정보와 기간에 따른 단/중/장기 예상 수익 비교를 통해 좀 더 활용성 높은 정보를 전달합니다!

추후에는 이러한 접속 유저의 예상 수익 지표를 바탕으로 1년간 발생한 총 매출을 추정하고 이와 관련된 보조 지표들을 개발하여 신뢰도 높은 지표로 고도화시킬 예정입니다. 이 밖에도 유저들의 기대 수명, 복귀 예상 고객 예측 등 정교한 고객 관리나 마케팅에 도움이 될 다양한 분석을 진행하여 조금이나마 활용성 높은 지표 생성에 기여할 수 있기를 바라며, 이만 글을 마칩니다. 

## Appendix.

**sBG(shifted Beta Geometric) 모델 설명**

sBG 모델이란, 기하/베타 분포를 이용하여 리텐션을 모델링 하는 방식으로, 유저의 이탈 확률이 베타 분포를 따른다고 가정하고, $$t$$ 시점에서의 이탈 확률과 생존 확률을 계산하여 리텐션 함수를 모델링하는 것 입니다. 세부 내용은 아래와 같습니다.

- 가정

  - sBG 모델에는 아래와 같이 크게 세 가지 가정이 필요합니다.

  - $$Θ$$: 유저의 이탈 확률, $$T=1$$ : 초기 시점 이라고 할 때,

    - $$t$$ 시점에서 유저의 이탈 확률:
      $$
      \begin{aligned}
      P( T=t | Θ ) = Θ \times (1-Θ)^{t-1}
      \end{aligned}
      $$

    - $$t$$ 시점에서 유저의 생존 확률:
      $$
      \begin{aligned}
      S( T=t | Θ ) = (1-Θ)^t
      \end{aligned}
      $$

    - 유저의 이탈 확률 $$Θ$$는 베타 분포를 따름:
      $$
      \begin{aligned}
      f( Θ | α , β ) = \frac{Θ^{α-1} \times (1-Θ)^{β-1}}{Β(α,β)}
      \end{aligned}
      $$
      

- 모델 설명

  - 유저의 이탈 확률 $$Θ$$가 베타 분포를 따른다는 가정을 이용하여 $$t$$ 시점에서 유저의 이탈 확률과 생존 확률을 추정합니다. 

  - $$Θ$$가 베타분포를 따른다는 가정을 이용하면 $$t$$시점에서의 유저의 이탈 확률과 생존확률은 다음과 같이 나타낼 수 있습니다.
    $$
    \begin{aligned}
    P( T=t | α , β ) = \frac{Β(α+1,β+t-1)}{Β(α,β)}, \ \ \ \ \ 
    S( T=t | α , β ) = \frac{Β(α,β+t)}{Β(α,β)}
    \end{aligned}
    $$

  - $$t$$시점에서의 유저의 생존 확률을 이용하면 $$t$$시점에서의 유저의 잔존 확률 $$r(t)$$는 다음과 같이 정의하며, 잔존 확률은 유저의 생존 확률 계산에 사용합니다.
    $$
    \begin{aligned}
    r_t = \frac{S(t)}{S(t-1)} = \frac{β+t-1}{α+β+t-1} , \ \ \ \ \ S(t) = r_t \times S(t-1)
    \end{aligned}
    $$
    
  - 이 때, $$α$$, $$β$$는 MLE를 사용하여 추정합니다.
    
  - 추정된 $$\hat{α}$$, $$\hat{β}$$을 이용하여 유저의 모든 시점의 생존 확률을 계산하여 리텐션 함수로 사용합니다.
    $$
    \begin{equation}
    S(T = 1) = \frac{β}{α+β}, \ \ \ \ \ 
    S(T = t) = r_t * S(T = t-1) = \frac{β + t -1}{α + β + t - 1} \times S(T = t-1)
    \end{equation}
    $$
  
- 중간에 생략된 수식 전개나 자세한 설명은 [HOW TO PROJECT CUSTOMER RETENTION](https://faculty.wharton.upenn.edu/wp-content/uploads/2012/04/Fader_hardie_jim_07.pdf)를 참고하시기 바랍니다.


**예상 수익 지표 신뢰구간**

- 크게 ARPU의 표준 오차와 리텐션의 표준 오차를 구하여 ARPU$\times$의 표준 오차로 신뢰구간을 계산합니다. 표준 오차 계산에 사용된 데이터의 갯수를 $$n$$이라고 하면 각각의 표준 오차는 아래와 같이 구할 수 있습니다.
  
  - 리텐션 함수는 sBG 모델 함수인 $$s(t)$$와 함수 피팅 방식으로 피팅된 분수 함수인 $$c(t)$$의 평균 값이며, 각각은 독립이라고 가정하면 아래와 같이 계산할 수 있습니다.
  
  $$
  \begin{equation}
  Var(R(t)) = Var( \frac{s(t) + c(t)}{2} ) =\frac{Var(s(t)) + Var(c(t))}{4}\ \ (s(t)와 \ c(t)는 \ 독립), \ \ \ \ \ \\
  Var(R(t)\times\hat{ARPU} ) = Var(R(t)\times Var(\hat{ARPU} ) + Var(R(t)\times[E(\hat{ARPU} )]^2 + Var(\hat{ARPU})\times[E(R(t))]^2 \ \ (R(t)와 \ \hat{ARPU}는 \ 독립) \\
  E(R(t))^2 = \frac{E(c(t))^2+E(s(t))^2}{4} + \frac{E(c(t))\times E(s(t))}{2}
  \end{equation}
  $$
  
- 따라서 최종 신뢰구간은 아래와 같습니다. 
  $$
  (LTV_{lower} , LTV_{upper}) = ( ∑\hat{ARPU} \times R(t) - 2.58 \times \sqrt\frac{Var(R(t))\times \hat{ARPU}}{n} , ∑\hat{ARPU} \times R(t) + 2.58 \times \sqrt\frac{Var(R(t))\times \hat{ARPU}}{n} )
  $$
  

 

